# services.py - Vers√£o Corrigida para Problemas de Token
from dotenv import load_dotenv
import os
import json
import re
from typing import List, Dict, Optional
from transformers import pipeline, AutoTokenizer

# -------------------------
# Config / ambiente
# -------------------------
load_dotenv()
HF_API_KEY = os.getenv("HF_API_KEY")
if HF_API_KEY:
    os.environ["HUGGINGFACE_HUB_TOKEN"] = HF_API_KEY
else:
    print("Aviso: HF_API_KEY n√£o encontrado no .env ‚Äî modelos privados/gated podem falhar.")

# -------------------------
# Modelos e pipelines otimizados para evitar problemas de token
# -------------------------
LED_MODEL = os.getenv("LED_MODEL", "allenai/led-base-16384")
SUM_MODEL_FALLBACK = os.getenv("SUM_MODEL_FALLBACK", "facebook/bart-large-cnn")
FLAN_MODEL = os.getenv("FLAN_MODEL", "google/flan-t5-large")

def safe_pipeline(task: str, model_name: str, device: int = -1, **kwargs):
    try:
        # Configura√ß√µes para evitar problemas de token
        if task == "summarization":
            kwargs.update({
                "max_length": 150,
                "min_length": 50,
                "do_sample": False,
                "truncation": True
            })
        elif task == "text2text-generation":
            kwargs.update({
                "max_length": 512,
                "do_sample": True,
                "temperature": 0.7,
                "truncation": True
            })
        
        return pipeline(task, model=model_name, device=device, **kwargs)
    except Exception as e:
        print(f"[safe_pipeline] Falha ao carregar {model_name}: {e}")
        return None

def safe_tokenizer(model_name: str):
    """Carrega tokenizer com configura√ß√µes seguras"""
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)
        return tokenizer
    except Exception as e:
        print(f"[safe_tokenizer] Falha ao carregar tokenizer {model_name}: {e}")
        return None

def truncate_text(text: str, tokenizer, max_tokens: int = 400) -> str:
    """Trunca texto para n√£o exceder limite de tokens"""
    if not tokenizer:
        # Fallback: truncar por caracteres (aproximadamente 4 chars = 1 token)
        max_chars = max_tokens * 4
        return text[:max_chars] if len(text) > max_chars else text
    
    try:
        # Tokenizar e truncar
        tokens = tokenizer.encode(text, truncation=True, max_length=max_tokens)
        return tokenizer.decode(tokens, skip_special_tokens=True)
    except Exception as e:
        print(f"[truncate_text] Erro: {e}")
        # Fallback por caracteres
        max_chars = max_tokens * 4
        return text[:max_chars] if len(text) > max_chars else text

# Carregamento seguro de modelos
print("[INFO] Carregando modelos com configura√ß√µes seguras...")

# Modelo para sumariza√ß√£o com fallback
summarizer_long = safe_pipeline("summarization", LED_MODEL)
if not summarizer_long:
    print("[INFO] LED model falhou, tentando BART...")
    summarizer_long = safe_pipeline("summarization", SUM_MODEL_FALLBACK)

# Tokenizer para sumariza√ß√£o
summ_tokenizer = safe_tokenizer(LED_MODEL)
if not summ_tokenizer:
    summ_tokenizer = safe_tokenizer(SUM_MODEL_FALLBACK)

# Modelos T5/FLAN com configura√ß√£o segura
resume_generator = safe_pipeline("text2text-generation", FLAN_MODEL)
resume_tokenizer = safe_tokenizer(FLAN_MODEL) if resume_generator else None

cover_letter_generator = resume_generator  # Reutilizar o mesmo modelo
generation_tokenizer = resume_tokenizer

print(f"[INFO] Modelos carregados:")
print(f"  - Summarizer: {'‚úì' if summarizer_long else '‚úó'}")
print(f"  - Resume Generator: {'‚úì' if resume_generator else '‚úó'}")
print(f"  - Tokenizers: {'‚úì' if summ_tokenizer else '‚úó'}")

# -------------------------
# Helpers de NLP (mantidos)
# -------------------------
KNOWN_TECH = [
    "Python", "JavaScript", "TypeScript", "C#", "Node.js", "React", "Next.js", "Vue.js",
    "TensorFlow", "PyTorch", "LangChain", "Hugging Face", "AWS", "S3", "DynamoDB", "Docker",
    "Kubernetes", "SQL", "Postgres", "MongoDB", "Redis", "GraphQL", "FastAPI", "Django",
    "Flask", "Angular", "Vue", "Svelte", "Go", "Rust", "Java", "Kotlin", "Swift"
]

def _sentences(text: str) -> List[str]:
    s = re.split(r'(?<=[\.\?\!])\s+', text)
    return [seg.strip() for seg in s if seg.strip()]

def _extract_techs(text: str) -> List[str]:
    txt = text.lower()
    found_techs = []
    for tech in KNOWN_TECH:
        if tech.lower() in txt:
            found_techs.append(tech)
    return found_techs

def _extract_roles(text: str) -> List[str]:
    patterns = ["desenvolvedor", "desenvolvedora", "analista", "engenheiro", "cientista", "gerente", "coordenador"]
    return [p for p in patterns if re.search(r'\b' + re.escape(p) + r'\b', text, flags=re.IGNORECASE)]

def _extract_projects(text: str) -> List[str]:
    projects = []
    lines = text.split('\n')
    
    in_projects_section = False
    for line in lines:
        line = line.strip()
        if 'projeto' in line.lower() and 'relevante' in line.lower():
            in_projects_section = True
            continue
        elif in_projects_section and line.startswith('- ') and ':' in line:
            projects.append(line[2:])
        elif in_projects_section and (line.startswith('Forma√ß√£o') or line.startswith('Habilidades')):
            in_projects_section = False
    
    return projects[:3]

def _extract_years_experience(text: str) -> Optional[str]:
    m = re.search(r'(\d+)\s*(anos|anos de|year|years)', text, flags=re.IGNORECASE)
    return f"{m.group(1)} anos" if m else None

def _extract_experience_lines(text: str) -> List[str]:
    lines = text.split('\n')
    experiences = []
    
    for line in lines:
        line = line.strip()
        if re.search(r'20\d{2}[‚Äì\-‚àí]\s*(presente|20\d{2})\s*:', line):
            experiences.append(line)
    
    return experiences

def _extract_education(text: str) -> Optional[str]:
    match = re.search(r'(bacharel|gradua√ß√£o|universidade|faculdade)[^0-9]*(\d{4})', text, re.IGNORECASE)
    if match:
        return match.group(0).strip()
    
    lines = text.split('\n')
    for line in lines:
        if any(word in line.lower() for word in ['universidade', 'faculdade', 'bacharel', 'gradua√ß√£o']):
            return line.strip()
    
    return None

def _extract_certifications(text: str) -> List[str]:
    lines = text.split('\n')
    certs = []
    
    in_cert_section = False
    for line in lines:
        line = line.strip()
        if 'certifica√ß' in line.lower():
            in_cert_section = True
            continue
        elif in_cert_section and line.startswith('- '):
            certs.append(line[2:])
        elif in_cert_section and line and not line.startswith('- '):
            in_cert_section = False
    
    return certs

# -------------------------
# Gerador program√°tico (mantido e melhorado)
# -------------------------
def _generate_resume_markdown_programmatic(resume_text: str, job_description: str) -> str:
    """Gerador program√°tico otimizado"""
    
    print("[DEBUG] Iniciando gera√ß√£o program√°tica de curr√≠culo")
    
    lines = [line.strip() for line in resume_text.strip().split('\n') if line.strip()]
    
    # Extrair informa√ß√µes b√°sicas
    name = lines[0] if lines else "Profissional"
    
    # Extrair tecnologias priorizando as da vaga
    all_techs = _extract_techs(resume_text + " " + (job_description or ""))
    job_techs = _extract_techs(job_description or "")
    priority_techs = [t for t in all_techs if t in job_techs] + [t for t in all_techs if t not in job_techs]
    
    # Extrair outras informa√ß√µes
    years_exp = _extract_years_experience(resume_text) or "3+ anos"
    experiences = _extract_experience_lines(resume_text)
    projects = _extract_projects(resume_text)
    education = _extract_education(resume_text)
    certifications = _extract_certifications(resume_text)
    
    # Determinar t√≠tulo baseado na vaga
    title = "Desenvolvedor/Engenheiro de IA"
    if job_description:
        job_lower = job_description.lower()
        if "fullstack" in job_lower:
            title = "Desenvolvedor Full Stack"
        elif "backend" in job_lower:
            title = "Desenvolvedor Backend"
        elif "frontend" in job_lower:
            title = "Desenvolvedor Frontend"
        elif "data scientist" in job_lower:
            title = "Cientista de Dados"
        elif "devops" in job_lower:
            title = "Engenheiro DevOps"
    
    # Construir curr√≠culo
    markdown = []
    
    # Header
    markdown.extend([
        f"# {name}",
        f"## {title}",
        "",
        "---",
        ""
    ])
    
    # Resumo Profissional
    markdown.extend([
        "## üíº Resumo Profissional",
        ""
    ])
    
    summary_parts = []
    summary_parts.append(f"Profissional com {years_exp} de experi√™ncia em desenvolvimento e tecnologia.")
    
    if "nlp" in resume_text.lower():
        summary_parts.append("Especialista em NLP e processamento de linguagem natural.")
    
    if "pipeline" in resume_text.lower():
        summary_parts.append("Experi√™ncia comprovada em constru√ß√£o de pipelines de ML e integra√ß√£o de modelos.")
    
    if priority_techs:
        main_techs = priority_techs[:4]
        if len(main_techs) > 1:
            summary_parts.append(f"Dom√≠nio t√©cnico em {', '.join(main_techs[:-1])} e {main_techs[-1]}.")
        else:
            summary_parts.append(f"Dom√≠nio t√©cnico em {main_techs[0]}.")
    
    for part in summary_parts:
        markdown.append(part)
        markdown.append("")
    
    # Experi√™ncia Profissional
    markdown.extend([
        "## üöÄ Experi√™ncia Profissional",
        ""
    ])
    
    if experiences:
        for exp in experiences[:3]:
            clean_exp = exp.replace('‚Äî', '-').replace('‚Äì', '-').replace(':', '')
            company_role = clean_exp.split('@')[0].strip() if '@' in clean_exp else clean_exp
            company = clean_exp.split('@')[1].split('‚Äî')[0].strip() if '@' in clean_exp else "Empresa"
            
            markdown.append(f"### {company_role}")
            markdown.append(f"**{company}** | {clean_exp.split()[0]} - {clean_exp.split()[1] if len(clean_exp.split()) > 1 else 'Presente'}")
            markdown.append("")
            
            # Adicionar bullets baseados no contexto
            bullets = []
            if "pipeline" in resume_text.lower():
                bullets.append("- Desenvolvimento e otimiza√ß√£o de pipelines de Machine Learning")
            if "api" in resume_text.lower():
                bullets.append("- Constru√ß√£o de APIs escal√°veis e integra√ß√£o de sistemas")
            if "aws" in resume_text.lower():
                bullets.append("- Deploy e gerenciamento de solu√ß√µes em cloud (AWS)")
            if not bullets:
                bullets = [
                    "- Desenvolvimento de solu√ß√µes tecnol√≥gicas inovadoras",
                    "- Colabora√ß√£o em projetos multidisciplinares"
                ]
            
            for bullet in bullets:
                markdown.append(bullet)
            markdown.append("")
    else:
        markdown.extend([
            "### Engenheiro de Machine Learning",
            "**TechCompany** | 2023 - Presente",
            "",
            "- Desenvolvimento de solu√ß√µes de IA e machine learning",
            "- Constru√ß√£o de pipelines de dados e modelos preditivos",
            "- Integra√ß√£o de LLMs em produtos e sistemas",
            "",
            "### Desenvolvedor Full Stack", 
            "**StartupTech** | 2021 - 2023",
            "",
            "- Desenvolvimento de aplica√ß√µes web e APIs",
            "- Implementa√ß√£o de solu√ß√µes de backend e frontend",
            "- Integra√ß√£o com servi√ßos de nuvem e databases",
            ""
        ])
    
    # Projetos Relevantes
    markdown.extend([
        "## üîß Projetos Relevantes",
        ""
    ])
    
    if projects:
        for i, project in enumerate(projects, 1):
            project_parts = project.split(':')
            project_name = project_parts[0].strip()
            project_desc = project_parts[1].strip() if len(project_parts) > 1 else "Projeto de tecnologia"
            
            markdown.append(f"### {i}. {project_name}")
            markdown.append(f"{project_desc}")
            markdown.append("")
    else:
        default_projects = [
            ("Sistema de Automa√ß√£o com IA", "Pipeline completo de processamento de dados com modelos de machine learning para classifica√ß√£o e predi√ß√£o."),
            ("API de Machine Learning", "Desenvolvimento de API REST escal√°vel para servir modelos ML em produ√ß√£o com monitoramento."),
            ("Plataforma de NLP", "Sistema de processamento de linguagem natural para an√°lise de sentimentos e extra√ß√£o de entidades.")
        ]
        
        for i, (name, desc) in enumerate(default_projects, 1):
            markdown.append(f"### {i}. {name}")
            markdown.append(f"{desc}")
            if priority_techs:
                relevant_techs = [t for t in priority_techs[:3]]
                if relevant_techs:
                    markdown.append(f"**Tecnologias:** {', '.join(relevant_techs)}")
            markdown.append("")
    
    # Habilidades T√©cnicas
    markdown.extend([
        "## üõ†Ô∏è Habilidades T√©cnicas",
        ""
    ])
    
    if priority_techs:
        # Categorizar tecnologias
        languages = [t for t in priority_techs if t in ['Python', 'JavaScript', 'TypeScript', 'C#', 'Java', 'Go', 'Rust']]
        frameworks = [t for t in priority_techs if t in ['React', 'Next.js', 'Vue.js', 'Node.js', 'FastAPI', 'Django', 'Flask']]
        ml_ai = [t for t in priority_techs if t in ['TensorFlow', 'PyTorch', 'LangChain', 'Hugging Face']]
        cloud_infra = [t for t in priority_techs if t in ['AWS', 'S3', 'DynamoDB', 'Docker', 'Kubernetes']]
        databases = [t for t in priority_techs if t in ['SQL', 'MongoDB', 'Postgres', 'Redis']]
        
        if languages:
            markdown.append(f"**Linguagens:** {', '.join(languages)}")
        if frameworks:
            markdown.append(f"**Frameworks:** {', '.join(frameworks)}")
        if ml_ai:
            markdown.append(f"**IA & ML:** {', '.join(ml_ai)}")
        if cloud_infra:
            markdown.append(f"**Cloud:** {', '.join(cloud_infra)}")
        if databases:
            markdown.append(f"**Databases:** {', '.join(databases)}")
    else:
        markdown.extend([
            "**Linguagens:** Python, JavaScript, TypeScript",
            "**IA & ML:** TensorFlow, PyTorch, LangChain",
            "**Cloud:** AWS, Docker, Kubernetes",
            "**Databases:** SQL, MongoDB, PostgreSQL"
        ])
    
    markdown.append("")
    
    # Forma√ß√£o
    if education:
        markdown.extend([
            "## üéì Forma√ß√£o",
            "",
            f"**{education}**",
            ""
        ])
    
    # Certifica√ß√µes
    if certifications:
        markdown.extend([
            "## üìú Certifica√ß√µes",
            ""
        ])
        for cert in certifications:
            markdown.append(f"- {cert}")
        markdown.append("")
    
    # Diferenciais competitivos
    if job_description:
        markdown.extend([
            "## ‚≠ê Diferenciais Competitivos",
            ""
        ])
        
        job_lower = job_description.lower()
        differentials = []
        
        # Mapear tecnologias encontradas para diferenciais
        tech_differentials = {
            "python": "‚úì **Expertise em Python** - linguagem principal para desenvolvimento",
            "javascript": "‚úì **JavaScript Avan√ßado** - desenvolvimento web moderno",
            "react": "‚úì **React Specialist** - interfaces de usu√°rio avan√ßadas",
            "aws": "‚úì **Cloud Computing** - experi√™ncia AWS para sistemas escal√°veis",
            "docker": "‚úì **Containeriza√ß√£o** - deploy e orquestra√ß√£o com Docker/Kubernetes",
            "api": "‚úì **APIs Escal√°veis** - desenvolvimento de servi√ßos robustos"
        }
        
        for tech_key, differential in tech_differentials.items():
            if tech_key in job_lower and any(tech.lower() in tech_key for tech in priority_techs):
                differentials.append(differential)
        
        # Adicionar diferenciais gen√©ricos se n√£o encontrar espec√≠ficos
        if not differentials:
            differentials = [
                "‚úì **Experi√™ncia t√©cnica alinhada** com os requisitos da posi√ß√£o",
                "‚úì **Capacidade comprovada** de entrega em projetos complexos"
            ]
        
        for diff in differentials[:4]:  # M√°ximo 4 diferenciais
            markdown.append(diff)
            markdown.append("")
    
    result = "\n".join(markdown)
    print(f"[DEBUG] Curr√≠culo gerado com {len(result)} caracteres")
    return result

# -------------------------
# Fun√ß√µes principais com prote√ß√£o contra problemas de token
# -------------------------
def summarize_resume(text: str) -> str:
    """Resumo com prote√ß√£o contra limite de tokens"""
    if not text.strip():
        return ""
    
    # Primeiro, tentar m√©todo simples
    sentences = _sentences(text)
    if len(sentences) <= 3:
        return text
    
    # Se temos o modelo de sumariza√ß√£o, usar com truncamento
    if summarizer_long and summ_tokenizer:
        try:
            # Truncar o texto para evitar problemas de token
            truncated_text = truncate_text(text, summ_tokenizer, max_tokens=400)
            print(f"[DEBUG] Texto truncado para {len(truncated_text)} caracteres")
            
            summary = summarizer_long(truncated_text)[0]['summary_text']
            print(f"[DEBUG] Resumo gerado: {len(summary)} caracteres")
            return summary
            
        except Exception as e:
            print(f"[ERROR] Erro na sumariza√ß√£o com modelo: {e}")
    
    # Fallback: m√©todo program√°tico
    key_sentences = []
    for sentence in sentences:
        if any(keyword in sentence.lower() for keyword in 
               ['experi√™ncia', 'desenvolvedor', 'engenheiro', 'analista', 'especialista', 'foco']):
            key_sentences.append(sentence)
        if len(key_sentences) >= 3:
            break
    
    if not key_sentences:
        key_sentences = sentences[:3]
    
    return " ".join(key_sentences)

def generate_optimized_resume(resume_text: str, job_description: Optional[str] = "") -> str:
    """Fun√ß√£o principal com fallbacks robustos"""
    print("[INFO] Gerando curr√≠culo otimizado")
    
    # Sempre tentar o gerador program√°tico primeiro (mais confi√°vel)
    try:
        return _generate_resume_markdown_programmatic(resume_text, job_description or "")
    except Exception as e:
        print(f"[ERROR] Erro no gerador program√°tico: {e}")
    
    # Se temos modelos carregados, tentar com eles
    if resume_generator and generation_tokenizer:
        try:
            # Criar prompt otimizado e truncado
            job_context = f"\n\nVaga: {job_description}" if job_description else ""
            prompt = f"Otimize este curr√≠culo:{job_context}\n\nCurr√≠culo:\n{resume_text}"
            
            # Truncar prompt para evitar problemas
            truncated_prompt = truncate_text(prompt, generation_tokenizer, max_tokens=350)
            print(f"[DEBUG] Prompt truncado para {len(truncated_prompt)} caracteres")
            
            result = resume_generator(truncated_prompt)[0]['generated_text']
            if result and len(result) > 100:
                print(f"[DEBUG] Curr√≠culo gerado via modelo: {len(result)} caracteres")
                return result
        except Exception as e:
            print(f"[ERROR] Erro na gera√ß√£o com modelo: {e}")
    
    # Fallback final: vers√£o b√°sica
    return f"""# Curr√≠culo Otimizado

## Resumo Profissional
{summarize_resume(resume_text)}

## Habilidades Principais
{', '.join(_extract_techs(resume_text + ' ' + (job_description or ''))[:8])}

## Experi√™ncia
Profissional com s√≥lida experi√™ncia em desenvolvimento de software e tecnologia.

---
*Curr√≠culo gerado automaticamente*"""

def generate_cover_letter(resume_text: str, job_description: Optional[str] = "") -> str:
    """Carta de apresenta√ß√£o com prote√ß√£o de token"""
    
    name_match = re.search(r'^([A-Za-z\s√Ä-√ø]+)', resume_text.strip())
    name = name_match.group(1).strip() if name_match else "Candidato"
    
    techs = _extract_techs(resume_text + " " + (job_description or ""))
    years = _extract_years_experience(resume_text) or "v√°rios anos"
    
    # Se temos o modelo, tentar usar
    if cover_letter_generator and generation_tokenizer:
        try:
            prompt = f"Escreva uma carta de apresenta√ß√£o profissional para {name} com {years} de experi√™ncia em {', '.join(techs[:3])}."
            truncated_prompt = truncate_text(prompt, generation_tokenizer, max_tokens=200)
            
            result = cover_letter_generator(truncated_prompt)[0]['generated_text']
            if result and len(result) > 50:
                return result
        except Exception as e:
            print(f"[ERROR] Erro na gera√ß√£o de carta: {e}")
    
    # Fallback program√°tico
    tech_list = ', '.join(techs[:4]) if techs else 'Python, Machine Learning, APIs'
    
    return f"""# Carta de Apresenta√ß√£o

**{name}**

---

Prezados senhores,

Tenho grande interesse na vaga anunciada e acredito que minha experi√™ncia de {years} na √°rea de desenvolvimento e tecnologia pode agregar valor significativo √† sua equipe.

Minha experi√™ncia t√©cnica inclui trabalho com {tech_list}, al√©m de s√≥lido background em desenvolvimento de solu√ß√µes escal√°veis e inovadoras.

Estou entusiasmado com a oportunidade de contribuir para os objetivos da empresa e aplicar meus conhecimentos em projetos desafiadores.

Agrade√ßo a considera√ß√£o e fico √† disposi√ß√£o para maiores esclarecimentos.

Atenciosamente,  
**{name}**
"""

def simulate_interview(resume_text: str, job_description: Optional[str] = "", max_retries: int = 1) -> List[Dict]:
    """Simulador de entrevista otimizado"""
    
    techs = _extract_techs(resume_text + " " + (job_description or ""))
    projects = _extract_projects(resume_text)
    years = _extract_years_experience(resume_text)
    
    qa = []
    
    # 1) Pergunta t√©cnica principal
    if techs:
        main_tech = techs[0]
        qa.append({
            "question": f"Descreva sua experi√™ncia pr√°tica com {main_tech}.",
            "answer": f"Tenho experi√™ncia s√≥lida com {main_tech}, desenvolvendo solu√ß√µes robustas e escal√°veis. Trabalho com essa tecnologia h√° {years or 'alguns anos'}, aplicando-a em projetos diversos."
        })
    
    # 2) Projetos espec√≠ficos
    if projects:
        qa.append({
            "question": "Conte sobre um projeto relevante que voc√™ desenvolveu.",
            "answer": projects[0]
        })
    else:
        qa.append({
            "question": "Descreva um projeto t√©cnico que voc√™ considera seu maior desafio.",
            "answer": "Desenvolvi um sistema completo de automa√ß√£o que resultou em melhoria significativa na efici√™ncia dos processos, utilizando tecnologias modernas e boas pr√°ticas de desenvolvimento."
        })
    
    # 3) Arquitetura e boas pr√°ticas
    qa.append({
        "question": "Como voc√™ garante a qualidade e escalabilidade dos seus sistemas?",
        "answer": "Aplico princ√≠pios de arquitetura limpa, uso de testes automatizados, containeriza√ß√£o com Docker, e implemento monitoramento cont√≠nuo. Sempre considero performance e manutenibilidade."
    })
    
    # 4) Trabalho em equipe
    qa.append({
        "question": "Como voc√™ trabalha em equipe multidisciplinar?",
        "answer": "Utilizo metodologias √°geis, mantenho comunica√ß√£o clara sobre progresso e desafios, documento bem o c√≥digo para facilitar a colabora√ß√£o, e estou sempre dispon√≠vel para apoiar colegas."
    })
    
    # 5) Motiva√ß√£o e fit cultural
    qa.append({
        "question": "Por que voc√™ tem interesse nesta posi√ß√£o?",
        "answer": "Estou motivado em aplicar minhas habilidades t√©cnicas para resolver problemas reais e contribuir com uma equipe que valoriza inova√ß√£o, crescimento profissional e excel√™ncia t√©cnica."
    })
    
    return qa